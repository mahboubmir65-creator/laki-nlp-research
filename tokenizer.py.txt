def laki_tokenizer(text):
    """???????? ???? ???? ???? ???"""
    tokens = text.split()
    return tokens

def analyze_poem(poem_lines):
    """????? ?????? ??? ???"""
    analysis = {
        'line_count': len(poem_lines),
        'avg_line_length': sum(len(line) for line in poem_lines) / len(poem_lines),
        'language': 'Laki',
        'dialect': 'Delfan'
    }
    return analysis

# ???? ???????
if name == "__main__":
    sample_poem = ["???? ??????", "???? ??? ???"]
    tokens = laki_tokenizer(sample_poem[0])
    analysis = analyze_poem(sample_poem)
    print("Tokens:", tokens)
    print("Analysis:", analysis)
